{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from webdriver_manager.chrome import ChromeDriverManager # chrome브라우저 버전에 맞는 드라이버인지 확인 및 없으면 다운로드\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n",
    "import time, json, logging, requests, os\n",
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # 로그 레벨 설정\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = {'산타페': [ # 차종\n",
    "            '산타페', # 해당 차종의 이명\n",
    "            '싼타페']\n",
    "       }\n",
    "BASE_URL = \"https://gall.dcinside.com/board/lists/?id=car_new1\"\n",
    "\n",
    "# 차량 출시일 / +3개월\n",
    "SEARCH_START = \"2023-08-16\"\n",
    "SEARCH_END = \"2023-11-16\"\n",
    "\n",
    "# 제목만 / 제목+내용\n",
    "SEARCH_URL_TITLE = f\"https://gall.dcinside.com/board/lists/?id=car_new1&s_type=search_subject&s_keyword={car['산타페'][1]}\"\n",
    "SEARCH_URL_TITLE_AND_CONTENT = f\"https://gall.dcinside.com/board/lists/?id=car_new1&s_type=search_subject_memo&s_keyword={car['산타페'][1]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3290091979.py, line 120)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 120\u001b[0;36m\u001b[0m\n\u001b[0;31m    if self.crawl_post_link(driver, soup): # 유효하지 않은 날짜를 만날 때 까지 크롤링\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class DC_crawler:\n",
    "    MAX_TRY = 2\n",
    "    RETRY_WAITS = 2\n",
    "    post_link = [\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, s_date, e_date, car_id):\n",
    "        self.start_date = s_date\n",
    "        self.end_date = e_date\n",
    "        self.car_id = car_id\n",
    "    \n",
    "    # Chrome WebDriver 선언\n",
    "    def _get_driver(self,):\n",
    "        # 이 path는 로컬 실행 시 주석처리 하세요.\n",
    "        # chrome_path = \"/opt/chrome/chrome-headless-shell-mac-arm64\"\n",
    "        # driver_path = \"/opt/chromedriver\"   \n",
    "\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # options.binary_location = chrome_path  # Chrome 실행 파일 지정 (로컬 실행 시 주석 처리)\n",
    "        options.add_argument(\"--headless\")  # Headless 모드\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"user-agent=Mozilla/5.0 (compatible; Daum/3.0; +http://cs.daum.net/)\")\n",
    "        options.add_argument(\"--window-size=1920x1080\")\n",
    "        \n",
    "        # service = Service(executable_path=\"/opt/chromedriver\")\n",
    "        driver = webdriver.Chrome(\n",
    "            # service=service, # 로컬 실행 시 주석 처리\n",
    "            options=options) \n",
    "        return driver\n",
    "    \n",
    "    def get_entry_point(self, driver:webdriver.Chrome, url=SEARCH_URL_TITLE):\n",
    "        s_date = self.start_date\n",
    "        e_date = self.end_date\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        # 🔹 1. 날짜 검색 창을 여는 버튼 클릭\n",
    "        #-----------------------------------------------\n",
    "        open_date_picker = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.btn_grey_roundbg.btn_schmove\")))\n",
    "        open_date_picker.click()\n",
    "        time.sleep(1)  # 검색 창이 뜨는 시간 고려\n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        # 🔹 2. 날짜 입력 필드 찾기\n",
    "        #-----------------------------------------------\n",
    "        date_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"input.dayin.calendar\")))\n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        # 🔹 3. 날짜 입력\n",
    "        #-----------------------------------------------\n",
    "        target_date = e_date  # 검색할 날짜\n",
    "        # JavaScript로 날짜 값 변경\n",
    "        driver.execute_script(\"arguments[0].value = arguments[1];\", date_input, target_date)\n",
    "        date_input.send_keys(target_date)\n",
    "        date_input.send_keys(Keys.RETURN)  # 엔터 입력\n",
    "\n",
    "        #-----------------------------------------------\n",
    "        # 🔹 4. 검색 버튼 클릭\n",
    "        #-----------------------------------------------\n",
    "        search_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.btn_blue.small.fast_move_btn\"))\n",
    "        )\n",
    "        search_btn.click()\n",
    "\n",
    "        #-----------------------------------------------\n",
    "        # 🔹 5. 검색 결과 로딩 대기\n",
    "        #-----------------------------------------------\n",
    "        time.sleep(0.5)  # 네트워크 환경에 따라 조정\n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        # 🔹 6. 페이지 소스 가져오기\n",
    "        #-----------------------------------------------\n",
    "        current_page_url = driver.current_url\n",
    "        return current_page_url        \n",
    "        \n",
    "        \n",
    "    def crawl_post_link(self, driver:webdriver.Chrome, soup:BeautifulSoup):\n",
    "        \"\"\"\n",
    "        현재 페이지에서 게시글들의 링크를 수집합니다.\n",
    "        \"\"\"\n",
    "        posts = soup.select(\"tr.ub-content.us-post\")\n",
    "        \n",
    "        date_changed = None\n",
    "        for post in posts:\n",
    "            # 날짜 검증\n",
    "            date = post.select_one(\"td.gall_date\").get_text(strip=True) if post.select_one(\"td_gall_date\") else \"날짜 없음\"\n",
    "\n",
    "            gall_num = int(post.select_one(\"td.gall_num\").get_text(strip=True))\n",
    "            dc_url = \"https://gall.dcinside.com\"\n",
    "            title_tag = post.select_one(\"td.gall_tit.ub-word a\")\n",
    "            link = dc_url + title_tag[\"href\"] if title_tag else \"링크 없음\"\n",
    "            \n",
    "            post_info = {\n",
    "                \"url\" : link,\n",
    "                \"id\" : gall_num,\n",
    "                \"date\" : date\n",
    "            }\n",
    "            \n",
    "            self.post_link.append(post_info)\n",
    "        return True\n",
    "    \n",
    "    def page_traveler(self, driver:webdriver.Chrome, current_link:str):\n",
    "        \"\"\"\n",
    "        페이징 박스를 순회합니다.\n",
    "        시간 역순으로 순회합니다. \n",
    "        (페이징 박스는 정방향 순회, 보이는 게시글은 시간 역순)\n",
    "        \"\"\"\n",
    "        random_sleep_time = [0.8, 0.6, 0.7, 0.5]\n",
    "        i = 0\n",
    "        # for _ in range(5):\n",
    "        driver.get(current_link)\n",
    "        web_source = driver.page_source\n",
    "        soup = BeautifulSoup(web_source, \"html.parser\")\n",
    "        return soup\n",
    "            if self.crawl_post_link(driver, soup): # 유효하지 않은 날짜를 만날 때 까지 크롤링\n",
    "                # 한 페이지를 다 긁었으면...\n",
    "                current_page = soup.find('em')\n",
    "                dc_url = \"https://gall.dcinside.com\"\n",
    "                next_link = current_page.find_next_sibling('a')\n",
    "                current_link = dc_url + next_link['href']\n",
    "                \n",
    "                if next_link['class'] == \"search_next\": \n",
    "                    logger.info(\"Search next 10000 posts\")\n",
    "                \n",
    "                time.sleep(random_sleep_time[i := i % 4])\n",
    "                i += 1\n",
    "            \n",
    "            else: # 특정 범위의 날짜를 전부 크롤링 했다면\n",
    "                logger.info(f\"crawling {self.start_date} ~ {self.end_date} finished\")\n",
    "                break\n",
    "        return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initiating Crawler\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Initiating Crawler\")\n",
    "crawler = DC_crawler(s_date=\"2023-08-16\", e_date=\"2023-11-16\", car_id=\"santafe\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = crawler._get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = crawler.get_entry_point(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gall.dcinside.com/board/lists/?id=car_new1&search_pos=-8697091&s_type=search_subject&s_keyword=.EC.8B.BC.ED.83.80.ED.8E.98'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = crawler.page_traveler(driver, endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m dc_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://gall.dcinside.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m next_link \u001b[38;5;241m=\u001b[39m current_page\u001b[38;5;241m.\u001b[39mfind_next_sibling(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m current_link \u001b[38;5;241m=\u001b[39m dc_url \u001b[38;5;241m+\u001b[39m \u001b[43mnext_link\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhref\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_link[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_next\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch next 10000 posts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "if crawler.crawl_post_link(driver, soup): # 유효하지 않은 날짜를 만날 때 까지 크롤링\n",
    "    # 한 페이지를 다 긁었으면...\n",
    "    current_page = soup.find('em')\n",
    "    dc_url = \"https://gall.dcinside.com\"\n",
    "    next_link = current_page.find_next_sibling('a')\n",
    "    current_link = dc_url + next_link['href']\n",
    "    \n",
    "    if next_link['class'] == \"search_next\": \n",
    "        logger.info(\"Search next 10000 posts\")\n",
    "    \n",
    "    # time.sleep(random_sleep_time[i := i % 4])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup\n",
    "current_page = soup.select_one('.bottom_paging_box.iconpaging em')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<em>1</em>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_url = \"https://gall.dcinside.com\"\n",
    "next_link = current_page.find_next_sibling('a')\n",
    "current_link = dc_url + next_link['href']\n",
    "\n",
    "if next_link.__class__ == \"search_next\": \n",
    "    logger.info(\"Search next 10000 posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
