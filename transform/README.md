# AWS Lambda 기반 데이터 변환 및 감성 분석 프로젝트

이 프로젝트는 AWS Lambda에서 실행되는 **데이터 변환 파이프라인**을 구현합니다.  
S3에 저장된 **Parquet 파일**을 불러와 **데이터 변환 작업을 수행**하고,  
필요에 따라 감성 분석을 수행한 후 결과를 다시 **S3에 저장**하는 방식으로 동작합니다.

---

## 📌 프로젝트 개요

1. **S3에서 Parquet 데이터 로드**  
2. **데이터 변환 수행 (Main Transform, Dynamic Transform)**  
3. **필요시 감성 분석 적용 (OpenAI API 활용)**  
4. **처리된 데이터를 S3에 저장**  
5. **AWS Lambda에서 자동 실행되도록 구성**  

---

## 📂 파일 구성

### 1️⃣ `main-transform-job.py`
- **정적인 데이터 변환 작업을 수행하는 스크립트**입니다.
- S3에서 데이터를 불러와 **사전에 정의된 변환 규칙**에 따라 데이터를 가공합니다.
- 변환 작업에는 다음과 같은 프로세스가 포함됩니다:
  - 날짜 형식 변환
  - 특정 열 데이터 정리
  - 새로운 컬럼 추가 (예: 카테고리 변환)
  - 불필요한 데이터 필터링
- 변환된 데이터를 새로운 Parquet 파일로 저장합니다.

### 2️⃣ `dynamic-transform-job.py`
- **동적인 데이터 변환을 수행하는 스크립트**입니다.
- 입력된 설정값(예: JSON 파라미터)에 따라 변환 로직이 동적으로 변경됩니다.
- 동적 변환 로직 예시:
  - 특정 필드 값 기준으로 데이터 필터링
  - 특정 열의 값을 다른 값으로 매핑
  - 조건부 데이터 변환 (예: 날짜 형식 변경, NULL 값 처리 등)
- **설정 기반 동작이 가능**하여 다양한 데이터 변환 시나리오에 유연하게 대응할 수 있습니다.

### 3️⃣ `main.py`
- **Lambda 함수의 엔트리포인트** (`lambda_handler`)를 포함합니다.
- S3에서 Parquet 데이터를 가져와 **지정된 변환 작업**을 실행합니다.
- 필요시 OpenAI API를 사용하여 **문장별 감성 분석**을 수행합니다.

### 4️⃣ `requirements.txt`
- 필요한 Python 패키지를 관리합니다.
- `boto3`, `pandas`, `pyarrow`, `openai` 등의 라이브러리가 포함됩니다.

### 5️⃣ `Dockerfile`
- AWS Lambda에서 실행될 환경을 설정하는 Dockerfile입니다.
- Python 및 의존성을 포함한 Lambda 컨테이너 이미지를 생성합니다.

---

## 🔄 전체 로직 (Workflow)

### 1️⃣ Lambda 핸들러 (`lambda_handler`)
AWS Lambda 실행 시 자동으로 호출되는 **엔트리포인트** 함수입니다.
- **이벤트 파라미터에서 S3 버킷과 폴더 경로를 가져옵니다.**
- **`process_all_files()`** 를 호출하여 변환 및 분석을 실행합니다.

### 2️⃣ 데이터 변환 (`main-transform-job.py`, `dynamic-transform-job.py`)
- **정적인 데이터 변환(`main-transform-job.py`)**
  - 미리 정의된 변환 규칙을 적용하여 데이터를 변환합니다.
  - 특정 필드 추가, 삭제, 변환 등의 작업을 수행합니다.
- **동적인 데이터 변환(`dynamic-transform-job.py`)**
  - 입력 설정값에 따라 변환 규칙이 다르게 적용됩니다.
  - 특정 조건을 만족하는 데이터만 필터링하거나, 컬럼 값 변환을 수행합니다.

### 3️⃣ 감성 분석 (필요시 적용, `request_openai_api`)
- OpenAI GPT-4 API를 사용하여 문장 감성을 분석합니다.
- 필요시 감성 분석 결과를 기존 데이터에 추가할 수 있습니다.

### 4️⃣ S3에 변환 및 분석 결과 저장
- **PyArrow를 이용해 DataFrame을 Parquet 포맷으로 변환합니다.**
- **S3에 새로운 Parquet 파일을 업로드하여 저장합니다.**

---

## 🚀 실행 방법

### 1️⃣ Docker 이미지 빌드
```bash
docker build -t lambda-data-transform .
```
- AWS Lambda에 배포할 컨테이너 이미지를 생성합니다.

### 2️⃣ Lambda 배포
1. 빌드된 이미지를 AWS ECR(Elastic Container Registry)에 푸시  
2. 해당 이미지를 Lambda 함수에 연결하여 실행  

### 3️⃣ Lambda 트리거 설정
- **S3 이벤트 트리거**를 설정하여 특정 폴더에 Parquet 파일이 업로드되면 자동 실행되도록 구성할 수 있습니다.

---

## 📝 정리

✅ **Lambda를 활용하여 자동화된 데이터 변환 수행**  
✅ **S3에서 데이터를 가져와 변환 후 저장**  
✅ **동적 변환 및 정적 변환 지원**  
✅ **필요시 감성 분석을 수행하여 부가 정보 추가 가능**  

이 프로젝트는 AWS Lambda와 Python을 활용하여 **데이터 변환을 자동화**하는 솔루션입니다.

